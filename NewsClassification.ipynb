{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Conv1D,MaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Model\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical\n",
    "import nltk \n",
    "#nltk.download()\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)\n",
    "from prettytable import PrettyTable\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>While the Congress seems to be in revival mode...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In Congress, it’s a problem of plenty with too...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Though the BJP leadership has been reportedly ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The political predicament also appears to be t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The party leadership, mainly PM Narendra Modi ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  1\n",
       "0  While the Congress seems to be in revival mode...  1\n",
       "1  In Congress, it’s a problem of plenty with too...  1\n",
       "2  Though the BJP leadership has been reportedly ...  0\n",
       "3  The political predicament also appears to be t...  0\n",
       "4  The party leadership, mainly PM Narendra Modi ...  1"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the data and store data in DataFrame titled news_data\n",
    "news_data = pd.read_csv(\"News_Dataset.csv\", header=None, skiprows=1, encoding='utf-8') \n",
    "# print a summary of the data in news_data\n",
    "news_data[1] = news_data[1].replace(['1-Septic', '0-Pure'], [1, 0])\n",
    "news_data[0] = news_data[0].replace('\\n', '', regex=True).str.strip()\n",
    "news_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data.dropna(axis=0, inplace=True)\n",
    "x = news_data[0]\n",
    "y = news_data[1]\n",
    "x_train , x_test ,y_train ,  y_test = train_test_split(x, y, test_size = 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=5000) #adding this parameter can  responsible for setting the size of the vocabulary i.e the most common num_words\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "x_train = tokenizer.texts_to_sequences(x_train)\n",
    "x_test = tokenizer.texts_to_sequences(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[[   1  377 1068 ...    0    0    0]\n",
      " [  78  169    1 ...    0    0    0]\n",
      " [   1  791    9 ...    0    0    0]\n",
      " ...\n",
      " [ 281    3  152 ...    0    0    0]\n",
      " [   1 1415   29 ...    0    0    0]\n",
      " [  21    9  682 ...    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "maxlen = 100\n",
    "x_train = pad_sequences(x_train, padding='post', maxlen=maxlen)\n",
    "x_test = pad_sequences(x_test, padding='post', maxlen=maxlen)\n",
    "print(type(x_train))\n",
    "# vocab_size = len(tokenizer.word_index) + 1  \n",
    "\n",
    "# data = []\n",
    "# punc = '.'\n",
    "# for i in x_train:\n",
    "#     i = i[:-1]\n",
    "#     token = word_tokenize(i)\n",
    "#     if punc in token:\n",
    "#         for index ,val in enumerate(token):\n",
    "#             if punc == val:\n",
    "#                 token.pop(index) \n",
    "# #      x_train = tokenizer.texts_to_sequences(token)\n",
    "# #    print(type(token))\n",
    "# #    token=np.array(token)\n",
    "#     data.append(token)\n",
    "# #     ' '.join(map(data,token ))\n",
    "# x_train = tokenizer.texts_to_sequences(data) \n",
    "# x_test = tokenizer.texts_to_sequences(x_test)\n",
    "# x_train=np.ndarray(x_train)\n",
    "# x_test=np.ndarray(x_test)\n",
    "# news_data.info()\n",
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN():\n",
    "    inputs = Input(name='inputs',shape=[maxlen])\n",
    "    layer = Embedding(5000,50,input_length=maxlen)(inputs)\n",
    "    layer = LSTM(64)(layer)\n",
    "    layer = Dense(256,name='FC1')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.5)(layer)\n",
    "    layer = Dense(1,name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_55\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_27 (Embedding)     (None, 100, 50)           250000    \n",
      "_________________________________________________________________\n",
      "lstm_27 (LSTM)               (None, 64)                29440     \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 296,337\n",
      "Trainable params: 296,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = RNN()\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy',optimizer=Adam(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.6446 - accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.5269 - accuracy: 0.7993\n",
      "Epoch 3/20\n",
      "12/12 [==============================] - 1s 76ms/step - loss: 0.5116 - accuracy: 0.7993\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - 1s 113ms/step - loss: 0.5016 - accuracy: 0.7993\n",
      "Epoch 5/20\n",
      "12/12 [==============================] - 1s 101ms/step - loss: 0.5062 - accuracy: 0.7993\n",
      "Epoch 6/20\n",
      "12/12 [==============================] - 1s 92ms/step - loss: 0.5055 - accuracy: 0.7993\n",
      "Epoch 7/20\n",
      "12/12 [==============================] - 1s 84ms/step - loss: 0.5068 - accuracy: 0.7993\n",
      "Epoch 8/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.5043 - accuracy: 0.7993\n",
      "Epoch 9/20\n",
      "12/12 [==============================] - 1s 79ms/step - loss: 0.5054 - accuracy: 0.7993\n",
      "Epoch 10/20\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.5045 - accuracy: 0.7993\n",
      "Epoch 11/20\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.5038 - accuracy: 0.7993\n",
      "Epoch 12/20\n",
      "12/12 [==============================] - 1s 80ms/step - loss: 0.5024 - accuracy: 0.7993\n",
      "Epoch 13/20\n",
      "12/12 [==============================] - 1s 88ms/step - loss: 0.5088 - accuracy: 0.7993\n",
      "Epoch 14/20\n",
      "12/12 [==============================] - 1s 90ms/step - loss: 0.5072 - accuracy: 0.7993\n",
      "Epoch 15/20\n",
      "12/12 [==============================] - 1s 87ms/step - loss: 0.5045 - accuracy: 0.7993\n",
      "Epoch 16/20\n",
      "12/12 [==============================] - 1s 91ms/step - loss: 0.5049 - accuracy: 0.7993\n",
      "Epoch 17/20\n",
      "12/12 [==============================] - 1s 88ms/step - loss: 0.5041 - accuracy: 0.7993\n",
      "Epoch 18/20\n",
      "12/12 [==============================] - 1s 83ms/step - loss: 0.5029 - accuracy: 0.7993\n",
      "Epoch 19/20\n",
      "12/12 [==============================] - 1s 84ms/step - loss: 0.5050 - accuracy: 0.7993\n",
      "Epoch 20/20\n",
      "12/12 [==============================] - 1s 94ms/step - loss: 0.5026 - accuracy: 0.7993\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2e3f3aeef0>"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,batch_size=128,epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 11ms/step - loss: 0.5304 - accuracy: 0.7778\n"
     ]
    }
   ],
   "source": [
    "accr = model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set\n",
      "  Loss: 0.530\n",
      "  Accuracy: 0.778\n"
     ]
    }
   ],
   "source": [
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 830us/step - loss: 0.2322 - accuracy: 1.0000\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "def mapper(a):\n",
    "    a = tokenizer.texts_to_sequences(a)\n",
    "    return pad_sequences(a, padding='post', maxlen=maxlen)\n",
    "\n",
    "\n",
    "x_eval = mapper(['he said, \"the world goes round and round and round\"',\n",
    "        'he said, \"the world has changed devastatingly\"'])\n",
    "\n",
    "y_eval = np.array([0, 0])\n",
    "model.evaluate(x_eval, y_eval)\n",
    "\n",
    "for i in model.predict(x_eval):\n",
    "    print(round(i[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[280,   0],\n",
       "       [ 80,   0]])"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_eval = model.predict(x_test)\n",
    "y_eval = [round(i[0]) for i in y_eval]\n",
    "confusion_matrix(y_test, y_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SC",
   "language": "python",
   "name": "sc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
